{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from transformers import BertConfig\n",
    "from model.model import MidiBert\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "print(\"Loading Dictionary\")\n",
    "with open('/Users/tobiaslandgraf/code/HugoA45/music_project/music_project/model/CP.pkl', 'rb') as f:\n",
    "    e2w, w2e = pickle.load(f)\n",
    "\n",
    "# Define the configuration for the BERT model\n",
    "configuration = BertConfig(\n",
    "    max_position_embeddings=512,\n",
    "    position_embedding_type='relative_key_query',\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "midibert = MidiBert(bertConfig=configuration, e2w=e2w, w2e=w2e)\n",
    "\n",
    "# Define the path to your checkpoint here\n",
    "ckpt_path = '/Users/tobiaslandgraf/code/HugoA45/music_project/music_project/model/pretrain_model.ckpt'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "# Remove the unexpected key from the state dictionary\n",
    "embeddings_position_ids =  checkpoint['state_dict'][\"bert.embeddings.position_ids\"]\n",
    "if \"bert.embeddings.position_ids\" in checkpoint['state_dict']:\n",
    "    del checkpoint['state_dict'][\"bert.embeddings.position_ids\"]\n",
    "\n",
    "# Load the state dictionary from the checkpoint into the model\n",
    "midibert.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/Users/tobiaslandgraf/code/HugoA45/music_project/music_project/data/pianist8/composer_cp_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 512, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 0],\n",
       "       [1, 1, 1, ..., 2, 2, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MidiBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(1023, 64)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (word_emb): ModuleList(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(4, 256)\n",
       "    )\n",
       "    (1): Embeddings(\n",
       "      (lut): Embedding(18, 256)\n",
       "    )\n",
       "    (2): Embeddings(\n",
       "      (lut): Embedding(88, 256)\n",
       "    )\n",
       "    (3): Embeddings(\n",
       "      (lut): Embedding(66, 256)\n",
       "    )\n",
       "  )\n",
       "  (in_linear): Linear(in_features=1024, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midibert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 512, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.from_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  6, 32, 23],\n",
       "         [ 0,  1, 44,  5],\n",
       "         [ 1,  3, 32,  5],\n",
       "         ...,\n",
       "         [ 1,  1, 37,  4],\n",
       "         [ 1,  2, 25,  2],\n",
       "         [ 1,  2, 13,  2]],\n",
       "\n",
       "        [[ 1,  4, 25,  4],\n",
       "         [ 1,  4, 49,  4],\n",
       "         [ 1,  4, 37,  4],\n",
       "         ...,\n",
       "         [ 1, 14, 20,  5],\n",
       "         [ 0,  0,  8, 45],\n",
       "         [ 1,  1, 20, 61]],\n",
       "\n",
       "        [[ 0,  1, 36, 63],\n",
       "         [ 1,  1, 63, 56],\n",
       "         [ 1,  1, 27,  0],\n",
       "         ...,\n",
       "         [ 1, 10, 56,  2],\n",
       "         [ 1, 11, 56,  1],\n",
       "         [ 1, 11, 68,  1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1, 11, 43,  7],\n",
       "         [ 1, 12, 24, 12],\n",
       "         [ 1, 12, 48,  4],\n",
       "         ...,\n",
       "         [ 1,  8, 36,  9],\n",
       "         [ 1,  8, 45, 17],\n",
       "         [ 1,  8, 17,  7]],\n",
       "\n",
       "        [[ 1,  8, 29,  9],\n",
       "         [ 1,  8, 33,  4],\n",
       "         [ 1, 11, 33,  4],\n",
       "         ...,\n",
       "         [ 1, 14, 16, 20],\n",
       "         [ 1, 15, 24, 14],\n",
       "         [ 0,  1, 28,  7]],\n",
       "\n",
       "        [[ 1,  2, 31,  1],\n",
       "         [ 1,  3, 31, 10],\n",
       "         [ 1,  3, 36, 10],\n",
       "         ...,\n",
       "         [ 2, 16, 86, 64],\n",
       "         [ 2, 16, 86, 64],\n",
       "         [ 2, 16, 86, 64]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
       "         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
       "         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
       "         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
       "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
       "         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
       "         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
       "         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
       "         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
       "         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
       "         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
       "         504, 505, 506, 507, 508, 509, 510, 511]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MidiBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(1023, 64)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (word_emb): ModuleList(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(4, 256)\n",
       "    )\n",
       "    (1): Embeddings(\n",
       "      (lut): Embedding(18, 256)\n",
       "    )\n",
       "    (2): Embeddings(\n",
       "      (lut): Embedding(88, 256)\n",
       "    )\n",
       "    (3): Embeddings(\n",
       "      (lut): Embedding(66, 256)\n",
       "    )\n",
       "  )\n",
       "  (in_linear): Linear(in_features=1024, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midibert.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = midibert(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (distance_embedding): Embedding(1023, 64)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midibert.bert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_position_ids.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eef9bbb5d149ab920a19a4b1f0fb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f76ae1758e4e0899d13f0629afbbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 109482240 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = midibert.bert.from_pretrained('bert-base-uncased')\n",
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f'The model has {num_parameters} parameters.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In a typical BERT model, the state_dict keys for the transformer layers usually follow this pattern:\n",
    "\n",
    "bert.encoder.layer.{i}.{sub_layer}.{param}\n",
    "where:\n",
    "\n",
    "{i} is the layer index (from 0 to 11 for a 12-layer BERT model),\n",
    "{sub_layer} is the sub-layer type, which can be attention.self, attention.output, intermediate, or output,\n",
    "{param} is the parameter type, which can be weight or bias for linear layers, and gamma or beta for layer normalization.\n",
    "To count the number of unique transformer layers in the state_dict, you can extract the layer index from each key and add it to a set (which automatically removes duplicates), then count the number of elements in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12 unique transformer layers.\n"
     ]
    }
   ],
   "source": [
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Initialize an empty set to store the layer indices\n",
    "layer_indices = set()\n",
    "\n",
    "# Iterate over the keys in the state dictionary\n",
    "for key in state_dict.keys():\n",
    "    # Split the key into parts\n",
    "    parts = key.split('.')\n",
    "    # If this key corresponds to a transformer layer\n",
    "    if parts[0] == 'bert' and parts[1] == 'encoder' and parts[2] == 'layer':\n",
    "        # Extract the layer index and add it to the set\n",
    "        layer_indices.add(int(parts[3]))\n",
    "\n",
    "# Print the number of unique layers\n",
    "print(f\"The model has {len(layer_indices)} unique transformer layers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_linear\n",
      "bert\n",
      "word_emb\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the layers\n",
    "layer_names = state_dict.keys()\n",
    "\n",
    "# Get the unique keys from the layers\n",
    "unique_keys = set()\n",
    "for name in layer_names:\n",
    "    # Split the name by '.' and get the first part\n",
    "    key = name.split('.')[0]\n",
    "    unique_keys.add(key)\n",
    "\n",
    "# Print the unique keys\n",
    "for key in unique_keys:\n",
    "    print(key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the state_dict keys for the transformer layers usually follow this pattern:\n",
    "\n",
    "bert.encoder.layer.{i}.{sub_layer}.{param}\n",
    "where:\n",
    "\n",
    "{i} is the layer index (from 0 to 11 for a 12-layer BERT model),\n",
    "{sub_layer} is the sub-layer type, which can be attention.self, attention.output, intermediate, or output,\n",
    "{param} is the parameter type, which can be weight or bias for linear layers, and gamma or beta for layer normalization.\n",
    "To count the number of unique transformer layers in the state_dict, you can extract the layer index from each key and add it to a set (which automatically removes duplicates), then count the number of elements in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
