{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from transformers import BertConfig\n",
    "from model.model import MidiBert\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "\n",
    "print(\"Loading Dictionary\")\n",
    "with open('/root/code/HugoA45/music_project/music_project/model/CP.pkl', 'rb') as f:\n",
    "    e2w, w2e = pickle.load(f)\n",
    "\n",
    "# Define the configuration for the BERT model\n",
    "configuration = BertConfig(\n",
    "    max_position_embeddings=512,\n",
    "    position_embedding_type='relative_key_query',\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=12\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "midibert = MidiBert(bertConfig=configuration, e2w=e2w, w2e=w2e)\n",
    "\n",
    "# Define the path to your checkpoint here\n",
    "ckpt_path = '/root/code/HugoA45/music_project/music_project/model/pretrain_model.ckpt'\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "\n",
    "# Remove the unexpected key from the state dictionary\n",
    "if \"bert.embeddings.position_ids\" in checkpoint['state_dict']:\n",
    "    embeddings_position_ids =  checkpoint['state_dict'][\"bert.embeddings.position_ids\"]\n",
    "    del checkpoint['state_dict'][\"bert.embeddings.position_ids\"]\n",
    "\n",
    "# Load the state dictionary from the checkpoint into the model\n",
    "midibert.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'state_dict', 'best_acc', 'valid_acc', 'valid_loss', 'train_loss', 'optimizer'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MidiBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (distance_embedding): Embedding(1023, 64)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (word_emb): ModuleList(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(4, 256)\n",
       "    )\n",
       "    (1): Embeddings(\n",
       "      (lut): Embedding(18, 256)\n",
       "    )\n",
       "    (2): Embeddings(\n",
       "      (lut): Embedding(88, 256)\n",
       "    )\n",
       "    (3): Embeddings(\n",
       "      (lut): Embedding(66, 256)\n",
       "    )\n",
       "  )\n",
       "  (in_linear): Linear(in_features=1024, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midibert.evasl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_position_ids.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_IncompatibleKeys' object has no attribute 'bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/root/code/HugoA45/music_project/music_project/notebooks/hugo.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/HugoA45/music_project/music_project/notebooks/hugo.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m midibert\u001b[39m.\u001b[39;49mbert\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/HugoA45/music_project/music_project/notebooks/hugo.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m num_parameters \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(p\u001b[39m.\u001b[39mnumel() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/root/code/HugoA45/music_project/music_project/notebooks/hugo.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe model has \u001b[39m\u001b[39m{\u001b[39;00mnum_parameters\u001b[39m}\u001b[39;00m\u001b[39m parameters.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'bert'"
     ]
    }
   ],
   "source": [
    "model = midibert.bert.from_pretrained('bert-base-uncased')\n",
    "num_parameters = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f'The model has {num_parameters} parameters.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In a typical BERT model, the state_dict keys for the transformer layers usually follow this pattern:\n",
    "\n",
    "bert.encoder.layer.{i}.{sub_layer}.{param}\n",
    "where:\n",
    "\n",
    "{i} is the layer index (from 0 to 11 for a 12-layer BERT model),\n",
    "{sub_layer} is the sub-layer type, which can be attention.self, attention.output, intermediate, or output,\n",
    "{param} is the parameter type, which can be weight or bias for linear layers, and gamma or beta for layer normalization.\n",
    "To count the number of unique transformer layers in the state_dict, you can extract the layer index from each key and add it to a set (which automatically removes duplicates), then count the number of elements in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12 unique transformer layers.\n"
     ]
    }
   ],
   "source": [
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "# Initialize an empty set to store the layer indices\n",
    "layer_indices = set()\n",
    "\n",
    "# Iterate over the keys in the state dictionary\n",
    "for key in state_dict.keys():\n",
    "    # Split the key into parts\n",
    "    parts = key.split('.')\n",
    "    # If this key corresponds to a transformer layer\n",
    "    if parts[0] == 'bert' and parts[1] == 'encoder' and parts[2] == 'layer':\n",
    "        # Extract the layer index and add it to the set\n",
    "        layer_indices.add(int(parts[3]))\n",
    "\n",
    "# Print the number of unique layers\n",
    "print(f\"The model has {len(layer_indices)} unique transformer layers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_emb\n",
      "in_linear\n",
      "bert\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the layers\n",
    "layer_names = state_dict.keys()\n",
    "\n",
    "# Get the unique keys from the layers\n",
    "unique_keys = set()\n",
    "for name in layer_names:\n",
    "    # Split the name by '.' and get the first part\n",
    "    key = name.split('.')[0]\n",
    "    unique_keys.add(key)\n",
    "\n",
    "# Print the unique keys\n",
    "for key in unique_keys:\n",
    "    print(key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the state_dict keys for the transformer layers usually follow this pattern:\n",
    "\n",
    "bert.encoder.layer.{i}.{sub_layer}.{param}\n",
    "where:\n",
    "\n",
    "{i} is the layer index (from 0 to 11 for a 12-layer BERT model),\n",
    "{sub_layer} is the sub-layer type, which can be attention.self, attention.output, intermediate, or output,\n",
    "{param} is the parameter type, which can be weight or bias for linear layers, and gamma or beta for layer normalization.\n",
    "To count the number of unique transformer layers in the state_dict, you can extract the layer index from each key and add it to a set (which automatically removes duplicates), then count the number of elements in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Bar', 'Position', 'Pitch', 'Duration'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2w.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'Bar New', 1: 'Bar Continue', 2: 'Bar <PAD>', 3: 'Bar <MASK>'},\n",
       " {0: 'Position 1/16',\n",
       "  1: 'Position 2/16',\n",
       "  2: 'Position 3/16',\n",
       "  3: 'Position 4/16',\n",
       "  4: 'Position 5/16',\n",
       "  5: 'Position 6/16',\n",
       "  6: 'Position 7/16',\n",
       "  7: 'Position 8/16',\n",
       "  8: 'Position 9/16',\n",
       "  9: 'Position 10/16',\n",
       "  10: 'Position 11/16',\n",
       "  11: 'Position 12/16',\n",
       "  12: 'Position 13/16',\n",
       "  13: 'Position 14/16',\n",
       "  14: 'Position 15/16',\n",
       "  15: 'Position 16/16',\n",
       "  16: 'Position <PAD>',\n",
       "  17: 'Position <MASK>'},\n",
       " {0: 'Pitch 22',\n",
       "  1: 'Pitch 23',\n",
       "  2: 'Pitch 24',\n",
       "  3: 'Pitch 25',\n",
       "  4: 'Pitch 26',\n",
       "  5: 'Pitch 27',\n",
       "  6: 'Pitch 28',\n",
       "  7: 'Pitch 29',\n",
       "  8: 'Pitch 30',\n",
       "  9: 'Pitch 31',\n",
       "  10: 'Pitch 32',\n",
       "  11: 'Pitch 33',\n",
       "  12: 'Pitch 34',\n",
       "  13: 'Pitch 35',\n",
       "  14: 'Pitch 36',\n",
       "  15: 'Pitch 37',\n",
       "  16: 'Pitch 38',\n",
       "  17: 'Pitch 39',\n",
       "  18: 'Pitch 40',\n",
       "  19: 'Pitch 41',\n",
       "  20: 'Pitch 42',\n",
       "  21: 'Pitch 43',\n",
       "  22: 'Pitch 44',\n",
       "  23: 'Pitch 45',\n",
       "  24: 'Pitch 46',\n",
       "  25: 'Pitch 47',\n",
       "  26: 'Pitch 48',\n",
       "  27: 'Pitch 49',\n",
       "  28: 'Pitch 50',\n",
       "  29: 'Pitch 51',\n",
       "  30: 'Pitch 52',\n",
       "  31: 'Pitch 53',\n",
       "  32: 'Pitch 54',\n",
       "  33: 'Pitch 55',\n",
       "  34: 'Pitch 56',\n",
       "  35: 'Pitch 57',\n",
       "  36: 'Pitch 58',\n",
       "  37: 'Pitch 59',\n",
       "  38: 'Pitch 60',\n",
       "  39: 'Pitch 61',\n",
       "  40: 'Pitch 62',\n",
       "  41: 'Pitch 63',\n",
       "  42: 'Pitch 64',\n",
       "  43: 'Pitch 65',\n",
       "  44: 'Pitch 66',\n",
       "  45: 'Pitch 67',\n",
       "  46: 'Pitch 68',\n",
       "  47: 'Pitch 69',\n",
       "  48: 'Pitch 70',\n",
       "  49: 'Pitch 71',\n",
       "  50: 'Pitch 72',\n",
       "  51: 'Pitch 73',\n",
       "  52: 'Pitch 74',\n",
       "  53: 'Pitch 75',\n",
       "  54: 'Pitch 76',\n",
       "  55: 'Pitch 77',\n",
       "  56: 'Pitch 78',\n",
       "  57: 'Pitch 79',\n",
       "  58: 'Pitch 80',\n",
       "  59: 'Pitch 81',\n",
       "  60: 'Pitch 82',\n",
       "  61: 'Pitch 83',\n",
       "  62: 'Pitch 84',\n",
       "  63: 'Pitch 85',\n",
       "  64: 'Pitch 86',\n",
       "  65: 'Pitch 87',\n",
       "  66: 'Pitch 88',\n",
       "  67: 'Pitch 89',\n",
       "  68: 'Pitch 90',\n",
       "  69: 'Pitch 91',\n",
       "  70: 'Pitch 92',\n",
       "  71: 'Pitch 93',\n",
       "  72: 'Pitch 94',\n",
       "  73: 'Pitch 95',\n",
       "  74: 'Pitch 96',\n",
       "  75: 'Pitch 97',\n",
       "  76: 'Pitch 98',\n",
       "  77: 'Pitch 99',\n",
       "  78: 'Pitch 100',\n",
       "  79: 'Pitch 101',\n",
       "  80: 'Pitch 102',\n",
       "  81: 'Pitch 103',\n",
       "  82: 'Pitch 104',\n",
       "  83: 'Pitch 105',\n",
       "  84: 'Pitch 106',\n",
       "  85: 'Pitch 107',\n",
       "  86: 'Pitch <PAD>',\n",
       "  87: 'Pitch <MASK>'},\n",
       " {0: 'Duration 0',\n",
       "  1: 'Duration 1',\n",
       "  2: 'Duration 2',\n",
       "  3: 'Duration 3',\n",
       "  4: 'Duration 4',\n",
       "  5: 'Duration 5',\n",
       "  6: 'Duration 6',\n",
       "  7: 'Duration 7',\n",
       "  8: 'Duration 8',\n",
       "  9: 'Duration 9',\n",
       "  10: 'Duration 10',\n",
       "  11: 'Duration 11',\n",
       "  12: 'Duration 12',\n",
       "  13: 'Duration 13',\n",
       "  14: 'Duration 14',\n",
       "  15: 'Duration 15',\n",
       "  16: 'Duration 16',\n",
       "  17: 'Duration 17',\n",
       "  18: 'Duration 18',\n",
       "  19: 'Duration 19',\n",
       "  20: 'Duration 20',\n",
       "  21: 'Duration 21',\n",
       "  22: 'Duration 22',\n",
       "  23: 'Duration 23',\n",
       "  24: 'Duration 24',\n",
       "  25: 'Duration 25',\n",
       "  26: 'Duration 26',\n",
       "  27: 'Duration 27',\n",
       "  28: 'Duration 28',\n",
       "  29: 'Duration 29',\n",
       "  30: 'Duration 30',\n",
       "  31: 'Duration 31',\n",
       "  32: 'Duration 32',\n",
       "  33: 'Duration 33',\n",
       "  34: 'Duration 34',\n",
       "  35: 'Duration 35',\n",
       "  36: 'Duration 36',\n",
       "  37: 'Duration 37',\n",
       "  38: 'Duration 38',\n",
       "  39: 'Duration 39',\n",
       "  40: 'Duration 40',\n",
       "  41: 'Duration 41',\n",
       "  42: 'Duration 42',\n",
       "  43: 'Duration 43',\n",
       "  44: 'Duration 44',\n",
       "  45: 'Duration 45',\n",
       "  46: 'Duration 46',\n",
       "  47: 'Duration 47',\n",
       "  48: 'Duration 48',\n",
       "  49: 'Duration 49',\n",
       "  50: 'Duration 50',\n",
       "  51: 'Duration 51',\n",
       "  52: 'Duration 52',\n",
       "  53: 'Duration 53',\n",
       "  54: 'Duration 54',\n",
       "  55: 'Duration 55',\n",
       "  56: 'Duration 56',\n",
       "  57: 'Duration 57',\n",
       "  58: 'Duration 58',\n",
       "  59: 'Duration 59',\n",
       "  60: 'Duration 60',\n",
       "  61: 'Duration 61',\n",
       "  62: 'Duration 62',\n",
       "  63: 'Duration 63',\n",
       "  64: 'Duration <PAD>',\n",
       "  65: 'Duration <MASK>'})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2e['Bar'], w2e['Position'], w2e['Pitch'], w2e['Duration']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
